{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68046437",
   "metadata": {},
   "source": [
    "# SP ENERGY NETWORKS Power Cuts - API Exploration\n",
    "\n",
    "**Goal:** Fetch and explore live power outage data from SP Energy Network. \n",
    "## API Endpoint <br>  \n",
    "**CKAN DataStore API:**  https://spenergynetworks.opendatasoft.com/api/explore/v2.1/catalog/datasets/distribution-network-live-outages/records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296cc3d",
   "metadata": {},
   "source": [
    "## 0. Setup And Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c075dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libaries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Display settings for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da55568",
   "metadata": {},
   "source": [
    "## 1. API Configurations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d067d887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Endpoint: https://spenergynetworks.opendatasoft.com/api/explore/v2.1/catalog/datasets/distribution-network-live-outages/records\n"
     ]
    }
   ],
   "source": [
    "# Base URL and dataset identifier\n",
    "BASE_URL = \"https://spenergynetworks.opendatasoft.com/api/explore/v2.1\"\n",
    "DATASET_ID = \"distribution-network-live-outages\"\n",
    "\n",
    "# Construct the full endpoint\n",
    "API_ENDPOINT = f\"{BASE_URL}/catalog/datasets/{DATASET_ID}/records\"\n",
    "\n",
    "print(f\"API Endpoint: {API_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569b6d3",
   "metadata": {},
   "source": [
    "## 2. Dataset Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a6c8bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET METADATA\n",
      "================================================================================\n",
      "Dataset ID: distribution-network-live-outages\n",
      "Title: Distribution Network Live Outages\n",
      "Description: <p>This \"<b>Distribution Network Live Outages</b>\" data table contains live outage data for SPEN's distribution network, covering both Low Voltage (LV) and High Voltage (HV) networks. The data is coll...\n",
      "\n",
      "Publisher: SP Energy Networks SC389555\n",
      "Modified: 2025-11-20T12:45:12+00:00\n",
      "Update Frequency: N/A\n",
      "Total Records: 31\n",
      "\n",
      "Themes: ['Network Usage']\n",
      "Keywords: ['Outages', 'Faults', 'Live']\n"
     ]
    }
   ],
   "source": [
    "# Get dataset metadata\n",
    "metadata_url = f\"{BASE_URL}/catalog/datasets/{DATASET_ID}\"\n",
    "\n",
    "response = requests.get(metadata_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    metadata = response.json()\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"DATASET METADATA\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Dataset ID: {metadata.get('dataset_id')}\")\n",
    "    print(f\"Title: {metadata['metas']['default'].get('title')}\")\n",
    "    print(\n",
    "        f\"Description: {metadata['metas']['default'].get('description', 'N/A')[:200]}...\")\n",
    "    print(f\"\\nPublisher: {metadata['metas']['default'].get('publisher')}\")\n",
    "    print(\n",
    "        f\"Modified: {metadata.get('metas', {}).get('default', {}).get('modified')}\")\n",
    "    print(\n",
    "        f\"Update Frequency: {metadata['metas']['default'].get('frequency', 'N/A')}\")\n",
    "    print(\n",
    "        f\"Total Records: {metadata.get('metas', {}).get('default', {}).get('records_count', 'N/A')}\")\n",
    "    print(f\"\\nThemes: {metadata['metas']['default'].get('theme', [])}\")\n",
    "    print(f\"Keywords: {metadata['metas']['default'].get('keyword', [])}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error fetching metadata: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101204b5",
   "metadata": {},
   "source": [
    "## 3. Dataset Schema Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ea98e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATASET SCHEMA - AVAILABLE COLUMNS\n",
      "================================================================================\n",
      "\n",
      "Total Fields: 10\n",
      "\n",
      "               Field Name                         Label     Type                                                     Description\n",
      "                 fault_id                      Fault ID     text            A unique identifier assigned to each fault incident.\n",
      "             licence_area                   DNO Licence     text  The license number of the Distribution Network Operator res...\n",
      "                   region                        Region     text  The geographical area or region where the outage incident t...\n",
      "                   status               Incident Status     text  The current status of the outage incident (e.g., ongoing, r...\n",
      "                  planned                       Planned  boolean              Indicates whether the outage was planned (yes/no).\n",
      "planned_outage_start_date          Planned Outage Start datetime          The scheduled start date and time for planned outages.\n",
      "   date_of_reported_fault           Fault Reported Date datetime                  The date and time when the fault was reported.\n",
      "                      etr Estimated Time of Restoration datetime  The estimated date and time by which the service is expecte...\n",
      "                  voltage                       Voltage     text  The voltage level of the network affected by the outage (e....\n",
      "          postcode_sector               Postcode Sector     text         The postal code of the location affected by the outage.\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DATASET SCHEMA - AVAILABLE COLUMNS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Extract field information\n",
    "    fields = metadata.get('fields', [])\n",
    "\n",
    "    print(f\"\\nTotal Fields: {len(fields)}\\n\")\n",
    "\n",
    "    # Create a DataFrame for better display\n",
    "    schema_data = []\n",
    "    for field in fields:\n",
    "        schema_data.append({\n",
    "            'Field Name': field.get('name'),\n",
    "            'Label': field.get('label'),\n",
    "            'Type': field.get('type'),\n",
    "            'Description': field.get('description', 'N/A')[:60] + '...' if field.get('description') and len(field.get('description', '')) > 60 else field.get('description', 'N/A')\n",
    "        })\n",
    "\n",
    "    schema_df = pd.DataFrame(schema_data)\n",
    "    print(schema_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dae90b",
   "metadata": {},
   "source": [
    "## 4. Fetch Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "872a0517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FETCHING SAMPLE DATA (First 5 records)\n",
      "================================================================================\n",
      "\n",
      "API Response Status: 200 - Success!\n",
      "Total Records Available: 31\n",
      "Records Retrieved: 31\n",
      "\n",
      "✓ Successfully retrieved sample data!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FETCHING SAMPLE DATA (First 5 records)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment\n",
    "API_KEY = os.getenv('SP_ENERGY_API_KEY')\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Apikey {API_KEY}\"\n",
    "}\n",
    "\n",
    "# Parameters for the API request\n",
    "params = {\n",
    "    \"limit\": 100,  # Get first 100 records\n",
    "    \"timezone\": \"Europe/London\"\n",
    "}\n",
    "\n",
    "# Make the API request\n",
    "response = requests.get(API_ENDPOINT, headers=headers, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    \n",
    "    print(f\"\\nAPI Response Status: {response.status_code} - Success!\")\n",
    "    print(f\"Total Records Available: {data.get('total_count', 'N/A')}\")\n",
    "    print(f\"Records Retrieved: {len(data.get('results', []))}\")\n",
    "    \n",
    "    # Check if we have results\n",
    "    if data.get('results'):\n",
    "        print(f\"\\n✓ Successfully retrieved sample data!\")\n",
    "    else:\n",
    "        print(\"\\n⚠ No records found in the dataset\")\n",
    "else:\n",
    "    print(f\"\\n✗ Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b57dc9",
   "metadata": {},
   "source": [
    "## 5. Display Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b10df1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAMPLE DATA - DATAFRAME VIEW\n",
      "================================================================================\n",
      "\n",
      "Shape: (31, 10)\n",
      "Columns: ['fault_id', 'licence_area', 'region', 'status', 'planned', 'planned_outage_start_date', 'date_of_reported_fault', 'etr', 'voltage', 'postcode_sector']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FIRST 5 RECORDS:\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fault_id</th>\n",
       "      <th>licence_area</th>\n",
       "      <th>region</th>\n",
       "      <th>status</th>\n",
       "      <th>planned</th>\n",
       "      <th>planned_outage_start_date</th>\n",
       "      <th>date_of_reported_fault</th>\n",
       "      <th>etr</th>\n",
       "      <th>voltage</th>\n",
       "      <th>postcode_sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INCD-906201-f</td>\n",
       "      <td>SP Distribution</td>\n",
       "      <td>STIRLING</td>\n",
       "      <td>Awaiting</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-11-20T09:00:00+00:00</td>\n",
       "      <td>2025-10-31T10:23:31+00:00</td>\n",
       "      <td>2025-11-20T15:30:00+00:00</td>\n",
       "      <td>HV</td>\n",
       "      <td>[FK8 3, FK7 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INCD-906759-f</td>\n",
       "      <td>SP Manweb</td>\n",
       "      <td>RUNCORN</td>\n",
       "      <td>Awaiting</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-11-20T09:00:00+00:00</td>\n",
       "      <td>2025-11-05T10:44:26+00:00</td>\n",
       "      <td>2025-11-20T16:00:00+00:00</td>\n",
       "      <td>HV</td>\n",
       "      <td>[CW9 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INCD-906849-f</td>\n",
       "      <td>SP Manweb</td>\n",
       "      <td>OSWESTRY NORTH</td>\n",
       "      <td>Awaiting</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-11-20T09:00:00+00:00</td>\n",
       "      <td>2025-11-05T15:58:14+00:00</td>\n",
       "      <td>2025-11-20T13:00:00+00:00</td>\n",
       "      <td>LV</td>\n",
       "      <td>[SY11 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INCD-907191-f</td>\n",
       "      <td>SP Manweb</td>\n",
       "      <td>GWYNEDD MENAI</td>\n",
       "      <td>Awaiting</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-11-20T09:00:00+00:00</td>\n",
       "      <td>2025-11-07T09:28:52+00:00</td>\n",
       "      <td>2025-11-20T16:00:00+00:00</td>\n",
       "      <td>HV</td>\n",
       "      <td>[LL65 3, LL65 4, LL71 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INCD-2389466-i</td>\n",
       "      <td>SP Manweb</td>\n",
       "      <td>GWYNEDD ERYRI</td>\n",
       "      <td>Awaiting</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-11-19T21:17:05+00:00</td>\n",
       "      <td>2025-11-20T16:00:00+00:00</td>\n",
       "      <td>HV</td>\n",
       "      <td>[LL53 8, LL53 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fault_id     licence_area          region    status  planned  \\\n",
       "0   INCD-906201-f  SP Distribution        STIRLING  Awaiting     True   \n",
       "1   INCD-906759-f        SP Manweb         RUNCORN  Awaiting     True   \n",
       "2   INCD-906849-f        SP Manweb  OSWESTRY NORTH  Awaiting     True   \n",
       "3   INCD-907191-f        SP Manweb   GWYNEDD MENAI  Awaiting     True   \n",
       "4  INCD-2389466-i        SP Manweb   GWYNEDD ERYRI  Awaiting    False   \n",
       "\n",
       "   planned_outage_start_date     date_of_reported_fault  \\\n",
       "0  2025-11-20T09:00:00+00:00  2025-10-31T10:23:31+00:00   \n",
       "1  2025-11-20T09:00:00+00:00  2025-11-05T10:44:26+00:00   \n",
       "2  2025-11-20T09:00:00+00:00  2025-11-05T15:58:14+00:00   \n",
       "3  2025-11-20T09:00:00+00:00  2025-11-07T09:28:52+00:00   \n",
       "4                       None  2025-11-19T21:17:05+00:00   \n",
       "\n",
       "                         etr voltage           postcode_sector  \n",
       "0  2025-11-20T15:30:00+00:00      HV            [FK8 3, FK7 9]  \n",
       "1  2025-11-20T16:00:00+00:00      HV                   [CW9 6]  \n",
       "2  2025-11-20T13:00:00+00:00      LV                  [SY11 3]  \n",
       "3  2025-11-20T16:00:00+00:00      HV  [LL65 3, LL65 4, LL71 7]  \n",
       "4  2025-11-20T16:00:00+00:00      HV          [LL53 8, LL53 6]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n",
      "=== Unique Values Analysis ===\n",
      "\n",
      "Unique values in 'status' column:\n",
      "['Awaiting' 'In Progress']\n",
      "Value counts: {'Awaiting': 30, 'In Progress': 1}\n",
      "\n",
      "Unique values in 'planned' column:\n",
      "[ True False]\n",
      "Value counts: {True: 18, False: 13}\n",
      "\n",
      "Data type of 'status': object\n",
      "Data type of 'planned': bool\n",
      "\n",
      "Sample Status + Planned combinations:\n",
      "         status  planned\n",
      "0      Awaiting     True\n",
      "4      Awaiting    False\n",
      "28  In Progress    False\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200 and data.get('results'):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SAMPLE DATA - DATAFRAME VIEW\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Extract fields from results\n",
    "    records_list = []\n",
    "    for record in data['results']:\n",
    "        # Opendatasoft often nests fields differently\n",
    "        # Try multiple possible structures\n",
    "        if 'fields' in record:\n",
    "            records_list.append(record['fields'])\n",
    "        elif 'record' in record and 'fields' in record['record']:\n",
    "            records_list.append(record['record']['fields'])\n",
    "        else:\n",
    "            records_list.append(record)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(records_list)\n",
    "\n",
    "    print(f\"\\nShape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"FIRST 5 RECORDS:\")\n",
    "    print(\"-\" * 80)\n",
    "    display(df.head())\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "    # Check unique values in Status and Planned columns\n",
    "    print(\"\\n=== Unique Values Analysis ===\")\n",
    "\n",
    "    if 'status' in df.columns:\n",
    "        print(f\"\\nUnique values in 'status' column:\")\n",
    "        print(df['status'].unique())\n",
    "        print(f\"Value counts: {df['status'].value_counts().to_dict()}\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ 'status' column not found in dataframe\")\n",
    "\n",
    "    if 'planned' in df.columns:\n",
    "        print(f\"\\nUnique values in 'planned' column:\")\n",
    "        print(df['planned'].unique())\n",
    "        print(f\"Value counts: {df['planned'].value_counts().to_dict()}\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ 'planned' column not found in dataframe\")\n",
    "\n",
    "    # Check data types\n",
    "    if 'status' in df.columns:\n",
    "        print(f\"\\nData type of 'status': {df['status'].dtype}\")\n",
    "    if 'planned' in df.columns:\n",
    "        print(f\"Data type of 'planned': {df['planned'].dtype}\")\n",
    "\n",
    "    # See sample combinations\n",
    "    print(f\"\\nSample Status + Planned combinations:\")\n",
    "    if 'status' in df.columns and 'planned' in df.columns:\n",
    "        print(df[['status', 'planned']].drop_duplicates().head(10))\n",
    "    elif 'status' in df.columns:\n",
    "        print(df[['status']].drop_duplicates().head(10))\n",
    "    elif 'planned' in df.columns:\n",
    "        print(df[['planned']].drop_duplicates().head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
